return(NULL)
},warning = function(war) {
print("Could not connect to PubMed")
return(NULL)
})
resQ1 <- resQ1[[2]]
resQ1
q
resQ1 <- tryCatch({
EUtilsSummary_custom(query = q,type = "esearch",db = "pubmed",
...)
},error = function(err) {
print("Could not connect to PubMed")
return(NULL)
},warning = function(war) {
print("Could not connect to PubMed")
return(NULL)
})
resQ1[[2]]
resQ1[[2]]@count
q
query
q <- "(\"FDG\"[all Fields]) OR (\"18f-fdg\"[All Fields]) OR (\"fluor-deoxyglucose\"[All Fields]) OR (\"18-fluor-deoxyglucose\"[All Fields])"
resQ1 <- tryCatch({
EUtilsSummary_custom(query = query,type = "esearch",db = "pubmed",
...)
},error = function(err) {
print("Could not connect to PubMed")
return(NULL)
},warning = function(war) {
print("Could not connect to PubMed")
return(NULL)
})
resQ1[[2]]
q
tryCatch({
EUtilsSummary_custom(query = query,type = "esearch",db = "pubmed",
...)
},error = function(err) {
print("Could not connect to PubMed")
return(NULL)
},warning = function(war) {
print("Could not connect to PubMed")
return(NULL)
})
resQ1 <- tryCatch({
EUtilsSummary_custom(query = query,type = "esearch",db = "pubmed",
...)
},error = function(err) {
print("Could not connect to PubMed")
return(NULL)
},warning = function(war) {
print("Could not connect to PubMed")
return(NULL)
})
resQ1 <- resQ1[[2]]
resQ1@count
resQ1
q = "(\"FDG\"[all Fields]) OR (\"18f-fdg\"[All Fields]) OR (\"fluor-deoxyglucose\"[All Fields]) OR (\"18-fluor-deoxyglucose\"[All Fields])"
resQ1 <- tryCatch({
EUtilsSummary_custom(query = query,type = "esearch",db = "pubmed",
...)
},error = function(err) {
print("Could not connect to PubMed")
return(NULL)
},warning = function(war) {
print("Could not connect to PubMed")
return(NULL)
})
resQ1 <- resQ1[[2]]
resQ1
q <- "(\"FDG\"[all Fields]) OR (\"18f-fdg\"[All Fields]) OR (\"fluor-deoxyglucose\"[All Fields]) AND ((\“APPPS1-21\”[All Fields]) OR (\“APP/PS1\”[All Fields]) OR (\“PS2APP\”[All Fields]) OR (\“TASTPM\”[All Fields]) OR (\“5XFAD\”[All Fields]) OR (\“3xTg\”[All Fields]))"
query
bartlett.test
findMethod("bartlett.test")
findMethods("bartlett.test")
findMethod("bartlett.test")
UseMethod("bartlett.test")
UseMethod(bartlett.test)
debug(bartlett.test)
require(graphics)
plot(count ~ spray, data = InsectSprays)
bartlett.test(InsectSprays$count, InsectSprays$spray)
x
x
v
sum(n * v)/n.total
STATISTIC
x
v
obj$df.resid
x
LM
n.total
sum(n * v)/n.total
k
PARAMETER
x <- list(n = NULL,
var = NULL)
x <- list(n = c(5,10), var = c(2, 6))
x
n <- x$n
v <- x$var
n.total <- sum(n)
sum(n * v)/n.total
v.total <- sum(n * v)/n.total
x <- list(n = c(5,10), var = c(2, 6), k = 2)
n <- x$n
v <- x$var
k <- x$k
n.total <- sum(n)
v.total <- sum(n * v)/n.total
STATISTIC <- ((n.total * log(v.total) - sum(n * log(v)))/(1 + (sum(1/n) - 1/n.total)/(3 * (k - 1))))
PARAMETER <- k - 1
PVAL <- pchisq(STATISTIC, PARAMETER, lower.tail = FALSE)
names(STATISTIC) <- "Bartlett's K-squared"
names(PARAMETER) <- "df"
list(statistic = STATISTIC, parameter = PARAMETER,
p.value = PVAL, data.name = DNAME, method = "Bartlett test of homogeneity of variances")
PVAL
STATISTIC
PARAMETER
print(STATISTIC,PARAMETER)
print(STATISTIC)
print(PARAMETER)
PVAL
print(STATISTIC)
print(PVAL)
print(PARAMETER)
shiny::runApp('DeboraGuerrini_MarcoAntonio/Oroboros/Sunyata')
source("/mnt/hd/Marco/Dropbox/DeboraGuerrini_MarcoAntonio/Oroboros/CustomFunction/OroborosTests.R")
path_to_files <- "/media/marcoantonio/KINGSTON/01. Excel 20D hyp OROBOROS"
input_list <- lapply(path_to_files, function(x){
read.csv(x, head = TRUE, sep = ",", na.strings = "", check.names = FALSE, stringsAsFactors = FALSE)
})
path_to_files
dir(path_to_files)
path_to_files <- "/media/marcoantonio/KINGSTON/01. Excel 20D hyp OROBOROS/HS1.csv"
input_list <- lapply(path_to_files, function(x){
read.csv(x, head = TRUE, sep = ",", na.strings = "", check.names = FALSE, stringsAsFactors = FALSE)
})
names(input_list) <- basename(path_to_files)
cnms_list <- lapply(input_list, colnames)
col_eval <- diff(sapply(cnms_list, length))
if(any(col_eval!=0)) {
stop("Input files have different column length.")
}
cnms <- cnms_list[[1]]
cnms_chamber <- cnms[grep(pattern = "A:|B:", x = cnms, ignore.case = TRUE)]
cnms_spl <- sapply(strsplit(x = cnms_chamber, split = ": "), "[[", 2)
names(cnms_chamber) <- cnms_spl
metrics <- cnms_chamber[grep(pattern = "flux", x = cnms_chamber, ignore.case = TRUE)]
metrics <- which(cnms%in%metrics)
delta_interval = 20
routine_event = NULL
column_metric = metrics
IQR_cutoff = 1
res_oro <- lapply(input_list, function(x) {
oroboros(data_input = x,
delta_interval = delta_interval,
routine_event = routine_event,
column_metric = column_metric)
})
source("/mnt/hd/Marco/Dropbox/DeboraGuerrini_MarcoAntonio/Oroboros/CustomFunction/OroborosFunctions.R")
res_oro <- lapply(input_list, function(x) {
oroboros(data_input = x,
delta_interval = delta_interval,
routine_event = routine_event,
column_metric = column_metric)
})
debug(oroboros)
res_oro <- lapply(input_list, function(x) {
oroboros(data_input = x,
delta_interval = delta_interval,
routine_event = routine_event,
column_metric = column_metric)
})
View(data_oroboros)
res_oro <- lapply(input_list, function(x) {
oroboros(data_input = x,
delta_interval = delta_interval,
routine_event = routine_event,
column_metric = column_metric)
})
View(data_oroboros)
# path_to_files <- c("/mnt/hd/Marco/Dropbox/DeboraGuerrini_MarcoAntonio/Oroboros/CustomFunction/Teste1.csv",
#                    "/mnt/hd/Marco/Dropbox/DeboraGuerrini_MarcoAntonio/Oroboros/CustomFunction/Teste2.csv",
#                    "/mnt/hd/Marco/Dropbox/DeboraGuerrini_MarcoAntonio/Oroboros/CustomFunction/Teste3.csv")
# path_to_files <- c("/mnt/hd/Marco/Dropbox/DeboraGuerrini_MarcoAntonio/Oroboros/CustomFunction/DebTest_C1XE1.csv",
#                    "/mnt/hd/Marco/Dropbox/DeboraGuerrini_MarcoAntonio/Oroboros/CustomFunction/DebTest_E2XC2.csv")
# path_to_files <- c("/mnt/hd/Marco/Dropbox/DeboraGuerrini_MarcoAntonio/Oroboros/CustomFunction/t1.csv",
#                    "/mnt/hd/Marco/Dropbox/DeboraGuerrini_MarcoAntonio/Oroboros/CustomFunction/t2.csv")
path_to_files <- c("/mnt/hd/Marco/Dropbox/DeboraGuerrini_MarcoAntonio/Oroboros/CustomFunction/DebTest_C1XE1.csv")
input_list <- lapply(path_to_files, function(x){
read.csv(x, head = TRUE, sep = ",", na.strings = "", check.names = FALSE, stringsAsFactors = FALSE)
})
names(input_list) <- basename(path_to_files)
cnms_list <- lapply(input_list, colnames)
col_eval <- diff(sapply(cnms_list, length))
if(any(col_eval!=0)) {
stop("Input files have different column length.")
}
cnms <- cnms_list[[1]]
cnms_chamber <- cnms[grep(pattern = "A:|B:", x = cnms, ignore.case = TRUE)]
cnms_spl <- sapply(strsplit(x = cnms_chamber, split = ": "), "[[", 2)
names(cnms_chamber) <- cnms_spl
metrics <- cnms_chamber[grep(pattern = "flux", x = cnms_chamber, ignore.case = TRUE)]
metrics <- which(cnms%in%metrics)
delta_interval = 20
routine_event = NULL
column_metric = metrics
IQR_cutoff = 1
res_oro <- lapply(input_list, function(x) {
oroboros(data_input = x,
delta_interval = delta_interval,
routine_event = routine_event,
column_metric = column_metric)
})
View(data_oroboros)
View(data_oroboros)
View(data_A)
View(data_input)
res_oro <- lapply(input_list, function(x) {
oroboros(data_input = x,
delta_interval = delta_interval,
routine_event = routine_event,
column_metric = column_metric)
})
path_to_files <- "/media/marcoantonio/KINGSTON/01. Excel 20D hyp OROBOROS/HS1.csv"
input_list <- lapply(path_to_files, function(x){
read.csv(x, head = TRUE, sep = ",", na.strings = "", check.names = FALSE, stringsAsFactors = FALSE)
})
names(input_list) <- basename(path_to_files)
cnms_list <- lapply(input_list, colnames)
col_eval <- diff(sapply(cnms_list, length))
if(any(col_eval!=0)) {
stop("Input files have different column length.")
}
cnms <- cnms_list[[1]]
cnms_chamber <- cnms[grep(pattern = "A:|B:", x = cnms, ignore.case = TRUE)]
cnms_spl <- sapply(strsplit(x = cnms_chamber, split = ": "), "[[", 2)
names(cnms_chamber) <- cnms_spl
metrics <- cnms_chamber[grep(pattern = "flux", x = cnms_chamber, ignore.case = TRUE)]
metrics <- which(cnms%in%metrics)
delta_interval = 20
routine_event = NULL
column_metric = metrics
IQR_cutoff = 1
res_oro <- lapply(input_list, function(x) {
oroboros(data_input = x,
delta_interval = delta_interval,
routine_event = routine_event,
column_metric = column_metric)
})
View(data_input)
data_oroboros[,c(1:5)]
column_metric
View(data_oroboros)
View(data_input)
View(data_oroboros)
View(data_input)
View(data_oroboros)
runApp('DeboraGuerrini_MarcoAntonio/Oroboros/Sunyata')
runApp('DeboraGuerrini_MarcoAntonio/Oroboros/Sunyata')
column_metric
runApp('DeboraGuerrini_MarcoAntonio/Oroboros/Sunyata')
runApp('DeboraGuerrini_MarcoAntonio/Oroboros/Sunyata')
path_to_files <- "/home/marcoantonio/Downloads/Fwd__oroboros_2/25.csv"
input_list <- lapply(path_to_files, function(x){
read.csv(x, head = TRUE, sep = ",", na.strings = "", check.names = FALSE, stringsAsFactors = FALSE)
})
names(input_list) <- basename(path_to_files)
cnms_list <- lapply(input_list, colnames)
col_eval <- diff(sapply(cnms_list, length))
if(any(col_eval!=0)) {
stop("Input files have different column length.")
}
cnms <- cnms_list[[1]]
cnms_chamber <- cnms[grep(pattern = "A:|B:", x = cnms, ignore.case = TRUE)]
cnms_spl <- sapply(strsplit(x = cnms_chamber, split = ": "), "[[", 2)
names(cnms_chamber) <- cnms_spl
metrics <- cnms_chamber[grep(pattern = "flux", x = cnms_chamber, ignore.case = TRUE)]
metrics <- which(cnms%in%metrics)
delta_interval = 20
routine_event = NULL
column_metric = metrics
IQR_cutoff = 1
res_oro <- lapply(input_list, function(x) {
oroboros(data_input = x,
delta_interval = delta_interval,
routine_event = routine_event,
column_metric = column_metric)
})
source("/mnt/hd/Marco/Dropbox/DeboraGuerrini_MarcoAntonio/Oroboros/CustomFunction/OroborosFunctions.R")
res_oro <- lapply(input_list, function(x) {
oroboros(data_input = x,
delta_interval = delta_interval,
routine_event = routine_event,
column_metric = column_metric)
})
debug(oroboros)
res_oro <- lapply(input_list, function(x) {
oroboros(data_input = x,
delta_interval = delta_interval,
routine_event = routine_event,
column_metric = column_metric)
})
View(data_A)
lapply(eventpoint_list, function(interval) {
stable_interval(einterval = interval,
data = data,
delta_interval = delta_interval,
IQR_cutoff = IQR_cutoff)
})
sapply(sinterval, function(x) {
metric <- x[[2]]
sum_dt <- summary(metric)
sum_dt <- c(sum_dt, sd = sd(metric), IQR = IQR(metric))
return(sum_dt)
})
View(sum_info)
chamber_int
View(data)
shiny::runApp('Captiomics/ASAP/Scripts/ASAP_v2')
library(epiR)
library(epiR)
## Generate data consistent with the information provided above. Assume the
## prevalence of high risk subjects in your population is 0.35:
set.seed(1234)
dat.df03 <- data.frame(out = rbinom(n = 200, size = 1, prob = 0.35),
bm = runif(n = 200, min = 0, max = 1))
View(dat.df03)
## Classify study subjects as either test positive or test negative
## according to their biomarker test result:
dat.df03$test <- ifelse(dat.df03$bm >= 0.6, 1, 0)
## Generate a two-by-two table:
dat.tab03 <- table(dat.df03$test, dat.df03$out)[2:1,2:1]
rval.tes03 <- epi.tests(dat.tab03, method = "exact", digits = 2,
conf.level = 0.95)
print(rval.tes03)
View(dat.df03)
View(dat.df03)
shiny::runApp('Captiomics/ASAP/Scripts/ASAP_v2')
runApp('Captiomics/ASAP/Scripts/ASAP_v2')
setwd("~/Desktop/Giovanna_meta_git/1_2_results_sensanalysis_woclinical")
#############################
# Data
#############################
files <- dir()
files <- files[grep(pattern = "Giovanna_MetaAnalysis.txt", x = files)]
data_original <- read.delim(file = files, header = TRUE, sep = "\t", dec = ",")
source(file = paste(dirname(getwd()), "MetaA_GregorAdapt_202206.R", sep = "/"))
#############################
# Data
#############################
files <- dir()
files <- files[grep(pattern = "Giovanna_MetaAnalysis.txt", x = files)]
data_original <- read.delim(file = files, header = TRUE, sep = "\t", dec = ",")
### Columns description ###
#### - study: list of different studies
#### - brain_region: list of brain regions in each study
#### - n_c: number of samples in reference group for each study
#### - m_c: mean of samples in reference group for each study
#### - sd_c: standard deviation in reference group for each study
#### - n_t: number of samples in test group for each study
#### - m_t: mean of samples in test group for each study
#### - sd_t: standard deviation in test group for each study
#### - n_s: number of subjects in study
colnames(data_original) <- tolower(colnames(data_original))
data_split <- split(x = data_original, f = data_original$table.id)
resList <- lapply(data_split, function(data) {
#############################
# Calculate Effect Sizes
#############################
data_escalc <- escalc(n1i = n_t, m1i = m_t, sd1i = sd_t, n2i = n_c, m2i = m_c, sd2i = sd_c, measure = "SMD",
data = data, vtype = "UB", append = F)
# I use vtype = UB in my publications, it's more conservative
data <- cbind(data, data_escalc)
dup <- data$study[duplicated(data$study)]
data_dup <- data[data$study%in%dup,]
data_unique <- data[!data$study%in%dup,]
row.names(data_unique) <- data_unique$study
if(nrow(data_dup)>0) {
n_samples <- split(x = data_dup, f = data_dup$study)
n_samples <- lapply(n_samples, function(x) c(sum(x$n_c), sum(x$n_t)))
n_samples <- do.call("rbind", n_samples)
colnames(n_samples) <- c("n_c", "n_t")
n_samples <- rbind(n_samples, data_unique[,c("n_c","n_t")])
colnames(n_samples) <- c("n_samples_c", "n_samples_t")
} else {
n_samples <- data_unique[,c("n_c","n_t")]
colnames(n_samples) <- c("n_samples_c", "n_samples_t")
}
#############################
# Combined SMD (adjusted standardized mean difference by fixed-effect model)
#############################
studs <- unique(data_dup$study)
res <- lapply(studs, function(x, dt) {
ourdata <- dt[dt$study==x,]
z <- rma.uni(yi = yi, vi = vi, measure = "SMD",
data = ourdata, method = "FE")
c(z[1],x)
}, dt = data_dup)
data_comb <- data_dup[!duplicated(data_dup$study),]
row.names(data_comb) <- data_comb$study
for(s in studs) {
data_comb[s, "n_c"] <- max(data_comb[s, "n_c"])
data_comb[s, "n_t"] <- max(data_comb[s, "n_t"])
}
data_comb$yi <- as.numeric(lapply(res, '[[',1))
data_comb$vi <- ((data_comb$n_c + data_comb$n_t)/(data_comb$n_c * data_comb$n_t) +
data_comb$yi^2)/(2*(data_comb$n_c + data_comb$n_t))
# here you have to be consistent with the vtype above
# (you can find the formula corresponding to your outcome measure in the escalc function script,
# for SMD and vtype UB  it is: (n1+n2)/(n1*n2) +y^2 / (2*(n1+n2)) )
#############################
# Random-effect model
#############################
data_final <- rbind(data_unique, data_comb)
data_final$ci_low <- data_final$yi - (stats::qnorm(1 - (1 - 0.95)/2) * as.numeric(sqrt(data_final$vi)))
data_final$ci_high <- data_final$yi + (stats::qnorm(1 - (1 - 0.95)/2) * as.numeric(sqrt(data_final$vi)))
data_final <- cbind(data_final, n_samples[data_final$study,])
row.names(data_final) <- data_final$id
data_final <- data_final[unique(data$id),]
res <- rma.uni(yi, vi, data = data_final, method="DL",
slab = paste(data_final$stud,
sep=""))
return(res)
})
table_indiv <- lapply(resList, function(x) {
d <- x$data
w <- weights(x)
d$weights <- w[d$study]
return(d)
})
table_indiv <- do.call("rbind", table_indiv)
row.names(table_indiv) <- NULL
table_synthesis <- lapply(resList, function(x) {
w <- weights(x)
fstats <- fitstats(x)[,1]
names(fstats) <- gsub(pattern = ":", replacement = "", x = names(fstats))
c("SMD" = round(x$beta, 2), "CI_lower" = round(x$ci.lb, 2),
"CI_upper" = round(x$ci.ub, 2), "pvalue" = round(x$pval,3), "zvalue" = round(x$zval,3),
"I2" = round(x$I2, 2), "tau2" = round(x$tau2, 2), round(fstats, 3),
# "weights" = paste(paste(names(w), round(w,2), sep = " = "), collapse = "; "),
"sum_sample_size_c" = sum(x$data$n_samples_c),
"sum_sample_size_t" = sum(x$data$n_samples_t),
"sum_indiv_size_c" = sum(x$data$n_c),
"sum_indiv_size_t" = sum(x$data$n_t))
})
table_synthesis <- do.call("rbind", table_synthesis)
table_synthesis <- data.frame("ID" = row.names(table_synthesis), table_synthesis,
stringsAsFactors = FALSE)
resList[[1]]
regtest(resList[[1]])
regtest(resList[[2]])
nm = names(resList)[2]
l = resList
x <- l[[nm]]
nrow(x$data)>2
egger <- regtest(x)
data.frame("ID" = nm, "Std_Eff" = c("slope", "bias"), "coefficient" = egger$fit$beta,
"std_error" = egger$fit$se, "zvalue" = egger$fit$zval,
"pvalue" = egger$fit$pval, "CI_low" = egger$fit$ci.lb,
"CI_high" = egger$fit$ci.ub)
egger$fit$beta
egger$fit
data.frame("ID" = nm, "Std_Eff" = c("slope", "bias"), "coefficient" = egger$fit$beta,
"std_error" = egger$fit$se, "zvalue" = egger$fit$zval,
"pvalue" = egger$fit$pval, "CI_low" = egger$fit$ci.lb,
"CI_high" = egger$fit$ci.ub)
regtest(x,predictor = "vi")
regtest(x,predictor = "ni")
regtest(x)
x
regtest(x,predictor = "sei")
regtest(x,predictor = "sei")$fit
regtest(x,predictor = "vi")$fit
table_egger <- lapply(names(resList), function(nm, l) {
x <- l[[nm]]
if(nrow(x$data)>2) {
egger <- regtest(x)
data.frame("ID" = nm, "Std_Eff" = c("intercept", "slope/bias"), "coefficient" = egger$fit$beta,
"std_error" = egger$fit$se, "zvalue" = egger$fit$zval,
"pvalue" = egger$fit$pval, "CI_low" = egger$fit$ci.lb,
"CI_high" = egger$fit$ci.ub)
} else {
data.frame("ID" = nm, "Std_Eff" = NA, "coefficient" = NA,
"std_error" = NA, "zvalue" = NA,
"pvalue" = NA, "CI_low" = NA,
"CI_high" = NA)
}
}, l = resList)
table_egger <- do.call("rbind", table_egger)
table_egger
table_egger <- lapply(names(resList), function(nm, l) {
x <- l[[nm]]
if(nrow(x$data)>2) {
egger <- regtest(x)
data.frame("ID" = nm, "Std_Eff" = c("intercept", "slope_bias"), "coefficient" = egger$fit$beta,
"std_error" = egger$fit$se, "zvalue" = egger$fit$zval,
"pvalue" = egger$fit$pval, "CI_low" = egger$fit$ci.lb,
"CI_high" = egger$fit$ci.ub)
} else {
data.frame("ID" = nm, "Std_Eff" = NA, "coefficient" = NA,
"std_error" = NA, "zvalue" = NA,
"pvalue" = NA, "CI_low" = NA,
"CI_high" = NA)
}
}, l = resList)
table_egger <- do.call("rbind", table_egger)
table_egger
